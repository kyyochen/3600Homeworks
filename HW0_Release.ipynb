{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCrCJKs28bGX"
      },
      "source": [
        "# Introduction To Jupyter Notebooks\n",
        "\n",
        "This is a notebook. It is an environment that mixes text and executable code. It is running in your browser and sends python code chunks to a backend server to execute. The backend server may be on your own computer, or on the cloud (in the case where you might be running on Google Colab).\n",
        "\n",
        "The environment makes it easy to write code (python) in small chunks and test those chunks separately. This is in contrast to writing code in a file and running the entire file. This makes it easy to prototype because you can go back and change small chunks of code and re-run those chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TA9t7J8NfCe"
      },
      "source": [
        "**1.** Notebooks are made up of *cells*. There are two types of cells. This piece of text you are reading now is a *text cell*. It is formatted using [Markdown](https://commonmark.org/), a lightweight alternative to HTML. Text cells are great ways to document your code. If you double-click this text you can edit it.\n",
        "\n",
        "The cell below this one is a *code cell*. The code in a code cell can be run by pushing the triangle \"play\" button. When you push the play button, the code is sent to a server running a python interpreter. The python interpreter executes the code and sends the result to be displayed below the code cell.\n",
        "\n",
        "Try running the code cell below here now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Uy9weMx8aJi"
      },
      "outputs": [],
      "source": [
        "print(\"hello world\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pemWgKMX9d5x"
      },
      "source": [
        "You should see ```hello world``` printed just under the cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqFVgywV9tRo"
      },
      "source": [
        "**2.** In the next code cell, we will create and manipulate some variables. Once a variable is created, it is accessible by all other cells. That is because the variables are now part of the python interpreter's state.\n",
        "\n",
        "Go ahead and run the cell just under this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGz-UiJ799IX"
      },
      "outputs": [],
      "source": [
        "x = 10\n",
        "y = x / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnfIZzcB-SRH"
      },
      "source": [
        "**3.** No output this time because variable assignments don't return values or print. How do we know it worked? Let's use another cell to check the values of ```x``` and ```y```. Run the next two cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaWPqlAq-ici"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbxtj_Mo-mQM"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GneSvepdMqCc"
      },
      "outputs": [],
      "source": [
        "x = x + 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okCibQZ5-yjV"
      },
      "source": [
        "If you need to change some code, you can change cells and run them again. Go back up to code cell under #2 and change the first line of the cell to ```x = 20```. Then run the code cells under #2 and #3 again.\n",
        "\n",
        "What happened? After you changed cell under #2 and ran it, the values of ```x``` and ```y``` changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om9VbbC9_Xpm"
      },
      "source": [
        "**4.** Since you can run cells in any order, you need to be careful. Run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHrmsOqe-xhS"
      },
      "outputs": [],
      "source": [
        "y = y * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwNf0yE-KqQM"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvVLAQ2ySJRi"
      },
      "source": [
        "What do you think is going to happen if we re-run the cells under #4, above?\n",
        "\n",
        "You should see that ```y``` is now equal to ```100.0```. Even though cell #3 is in the notebook before cell #4, the python interpreter's internal state has changed and the cells respond accordingly.\n",
        "\n",
        "You might have noticed that after you run a cell, a number appears in the place of the run buttom. This tells you what order the cells have been run in. So now the execution number for cell #3 is larger than the execution number for cell #4. This tells you that cell #3 may have been affected by anything that ran in cell #4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLDDQCS_BAXV"
      },
      "source": [
        "**6.** Let's get a bit fancier. Run the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Pi9NmSgBHTS"
      },
      "outputs": [],
      "source": [
        "def my_function(x):\n",
        "  return x ** 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewbMohOYBNSS"
      },
      "source": [
        "**7.** You just created a function that takes any value and multiplies to by 2 (very fancy!). Like variables, this function is now part of the python interpreter's internal state. You can call the function from other cells, like the one below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYjGxowNBYdn"
      },
      "outputs": [],
      "source": [
        "my_function(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP1whEVuBdlV"
      },
      "source": [
        "You should have gotten a six.\n",
        "\n",
        "But wait, I meant to make the function *square* the number. We'd better fix that. Go back up to cell #6 and change the code so that it reads:\n",
        "```\n",
        "def my_function(x):\n",
        "  return x ** 2\n",
        "```\n",
        "(Note the double asterisks, which is the python operator raise x to exponentiate.)\n",
        "\n",
        "After you have done that run the cell under #6 again and then run the cell under #7 again. The cell under #7 should now output 9 (which is 3^2).\n",
        "\n",
        "A really good coding practice is to write functions in cells and then test them in other cells. This is called *unit testing*. You can work on a function until you know it is right and then you can go on to the next part of a program and use that earlier function to make something more sophisticated (and test that too).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_6E-UADTqht"
      },
      "source": [
        "**8.** You can create new code cells. Depending on whether you are running jupyter lab or Google Colab, the interface will be different. Most likely there is a button on or near the menu bar with a \"+\".\n",
        "\n",
        "Create a new code cell just below here and write a function called `is_odd(x)` that determines if x is odd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoyEAfBmQeY_"
      },
      "outputs": [],
      "source": [
        "def is_odd(x):\n",
        "  return x % 2 == 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pbxvGmOQlzW"
      },
      "outputs": [],
      "source": [
        "is_odd(101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wXj7fI9V2zk"
      },
      "source": [
        "If you ran your new cell, then the python interpreter should now know your function. If you ran the cell and you got an interpreter error, you can fix your python syntax and run it again until you don't get an error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9eHQbPmWV8A"
      },
      "source": [
        "**9.** We should probably make sure your `is_odd` function is correct. Create a new code cell just below and try out some test cases like `is_odd(0)`, and `is_odd(1)`, `is_odd(100)`, and `is_odd(101)`. Run each of these statements and verify that the outputs are correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97HuhnhuHao5"
      },
      "source": [
        "**10.** Here are some other useful things you should know about notebooks.\n",
        "\n",
        "If you want to get rid of all the variables and function in the python interpreter's internal state, use the menu options at the top to \"Restart Kernel\" or \"Restart Runtime\". These are under either the \"Kernel\" or \"Runtime\" menus. This kills the python interpreter and restarts it in a fresh state.\n",
        "\n",
        "You can run more than one cell at a time. There will be menu options for \"Run all\", \"Run all above selected cell\".\n",
        "\n",
        "It is generally a good idea before you are done to make sure your notebook runs from start to finish in order. Make sure to always do one last \"Run all\". If you've been running cells in non-linear order, which is often the case when you are debugging something, then you might have introduced something in a later cell that changes how an earlier cell works.\n",
        "\n",
        "If you have a cell that gets stuck in an infinite loop or is running too long, there is an option to \"Interrupt kernel\" or \"interrupt execution\". This is the equivalent of CTRL-C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYp1M9p4ihci"
      },
      "source": [
        "# Text Adventure Games"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ao-NQxZsKPD"
      },
      "source": [
        "*Text Adventure Games* are games in which the player interacts with a rich world only through text. Text adventure games predate computers with graphics. However, in many ways they are more complex than conventional video games because they can involve complicated interactions (e.g., \"build a rope bridge\") that require a fair amount of imagination. Indeed, text adventure games are used as [research testbeds](https://arxiv.org/abs/1909.05398) for natural language processing agents.\n",
        "\n",
        "The canonical text adventure game is [Zork](https://en.wikipedia.org/wiki/Zork), in which the player discover an abandoned underworld realm full of treasure. You can find online playable versions.\n",
        "\n",
        "A text game is made up of individual locations--also called \"rooms\", though they need not be indoor enclosed spaces as the term might imply. The agent can move between rooms and interact with objects by typing in short commands like \"move north\" and \"take lamp\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Rtov8a2lsy"
      },
      "source": [
        "# TextWorld-Express"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNdTinxy0YFc"
      },
      "source": [
        "[TextWorld-Express](https://github.com/cognitiveailab/TextWorldExpress) is a lightweight python package that emulates very simple text games.\n",
        "\n",
        "For simplicity, TextWorld-Express worlds are laid out on grids, with the ability to move only between certain rooms. In some cases, there may be doors between rooms that need to be opened before moving.\n",
        "\n",
        "TextWorld-Express supports several different types of games, with their own win conditions. We will focus on two games in particular:\n",
        "- Coin Game: a simple game in which the agent must search for and pick up a single coin.\n",
        "- Map Reader: a game in which the agent must find a key and return it to a box at the starting location."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3lgj4WqsOZd"
      },
      "source": [
        "Install the Textworld-Express package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6WZ62u2sRaD"
      },
      "outputs": [],
      "source": [
        "!pip install textworld-express\n",
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW-d3VH5sS8Y"
      },
      "source": [
        "Load the package into the interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWPGWyvbsVaZ"
      },
      "outputs": [],
      "source": [
        "from textworld_express import TextWorldExpressEnv\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXWSFg_sst1d"
      },
      "source": [
        "Get an instance of a TextWorld-Express environment. An *environment* is an API that allows an agent to get observations and to perform actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4kojxW1se-g"
      },
      "outputs": [],
      "source": [
        "env = TextWorldExpressEnv(envStepLimit=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwmKAfiLtDw_"
      },
      "source": [
        "This is an empty environment. What should be in the environment? Rooms, doors, objects, coins, other things? The following tells the TextWorld-Express package what the game world should contain, and what the \"rules\" of the game should be.\n",
        "\n",
        "In this case, we will load the Coin Game rules. In this game, the agent must find a coin somewhere in the world and pick it up. We are also specifying that there should be five rooms (locations), and there should be doors between each room."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEz4fwafsl6N"
      },
      "outputs": [],
      "source": [
        "env.load(gameName=\"coin\", gameParams=\"numLocations=5,includeDoors=1,numDistractorItems=3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyFlVSBit0ob"
      },
      "source": [
        "Next we reset the environment. This is always done before starting to interact with the environment. We will give it a seed, which will initialize a random number generator. Each time the seed is changed, the rooms, doors, and objects will be different.\n",
        "\n",
        "`reset()` returns two values. The first is an \"observation\", which is what the agent can directly observe. In this case it is the text that describes the room that the agent is in. The second is a dictionary with additional information about the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSQsyib2twOc"
      },
      "outputs": [],
      "source": [
        "obs, infos = env.reset(seed=3, gameFold=\"train\", generateGoldPath=True)\n",
        "print('obs:', obs)\n",
        "print('infos:', infos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdyBWqeRucpA"
      },
      "source": [
        "While in a text game you can type anything you want as an action, there are only a few commands that will actually do anything useful. These are called the \"valid actions\". You can see what they are like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHOEiLCVumXb"
      },
      "outputs": [],
      "source": [
        "validActions = infos['validActions']\n",
        "print(validActions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI7VLm3jusKg"
      },
      "source": [
        "Let's choose a random action and execute it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7x7WX2suugX"
      },
      "outputs": [],
      "source": [
        "obs, reward, done, infos = env.step('move south')\n",
        "print(obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7Y7_HgQu4eK"
      },
      "source": [
        "The `step()` function performs the requested action. The function returns several values:\n",
        "- `observation`: the text response. If the action is a move action, the text response will be the description of the new room. Otherwise, it will be text that describes your action and the outcome. Some actions, like closing a door that is already closed, or trying to go through a door that is not open will result in a message that that action could not be performed.\n",
        "\n",
        "- `reward`: reward is a numerical value that indicates whether that action is good (positive) or bad (negative). Most actions produce 0 reward because they are inherently neither good or bad. This is helpful for agents that learn.\n",
        "\n",
        "- `done`: a boolean indicating whether the game has terminated or not.\n",
        "\n",
        "- `infos`: a dictionary of additional information about the environment\n",
        "  - `observation`: the agent's last observation\n",
        "\n",
        "  - `look`: what the agent will observe if they executed the 'look' action (not always the same as the observation)\n",
        "\n",
        "  - `inventory`: what the agent has in inventory\n",
        "\n",
        "  - `validActions`: the actions the agent can take, regardless of whether they will be successful\n",
        "\n",
        "  - `reward`: the last reward the agent received\n",
        "\n",
        "  - `done`: whether the game has terminated\n",
        "  \n",
        "  - There are other elements as well that you will unlikely need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAFbzL4lOpMD"
      },
      "outputs": [],
      "source": [
        "infos['look']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxEMeY-cv_E3"
      },
      "source": [
        "When the environment is generated, the \"gold path\" is also generated. This is a sequence of actions that is guaranteed to complete the game successfully. The gold path is not guaranteed to be optimal. It is secret information. An AI agent should never access this information. It is helpful for debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN0YODflv6q6"
      },
      "outputs": [],
      "source": [
        "gold = env.getGoldActionSequence()\n",
        "print(gold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBdLWYPqwa1C"
      },
      "source": [
        "# Interactive Mode\n",
        "\n",
        "Run this to play the game worlds yourself. Actions are:\n",
        "- `look around`\n",
        "- `move <north, south, east, west>`\n",
        "- `open door to  <north, south, east, west>`\n",
        "- `take <item>` # wht are the items here\n",
        "\n",
        "Type `exit` to quit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JywOxDUgwfuF"
      },
      "outputs": [],
      "source": [
        "# Reset the environment\n",
        "obs, infos = env.reset(seed=3, gameFold=\"train\")\n",
        "cmd = '' # the user's command\n",
        "# Iterate until the user enters 'exit'\n",
        "while cmd != 'exit':\n",
        "  # print the state\n",
        "  print(obs, '\\n')\n",
        "  # get the user's next command\n",
        "  cmd = input(\">> \")\n",
        "  if cmd != 'exit':\n",
        "    # execute the user's command\n",
        "    obs, reward, done, infos = env.step(cmd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZKYpjodw9xJ"
      },
      "source": [
        "# Test Environment\n",
        "\n",
        "In this assignment, we will create an agent whose job it is to visit every location in the world at least once. We will build on top of CoinGame, so picking up the coin will also terminate the game.\n",
        "\n",
        "**So if the agent picks up the coin before visiting all the locations in the world, it will not score well. Therefore, don't pick up the coin!!.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTgtEX38QpNh"
      },
      "source": [
        "## Some more imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_LgUfpYyhpo"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import inspect\n",
        "import gymnasium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoVHTZfP3c-u"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S61L6ad93hPT"
      },
      "source": [
        "Parse the name of the location out of the observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51hKsMiozD7-"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "def get_location_from_obs(obs):\n",
        "  match = re.search(r'You are in the ([a-zA-Z0-9 ]+).', obs)\n",
        "  if match is not None and len(match.groups()) >= 1:\n",
        "    return match.group(1)\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lDTXGh63mib"
      },
      "source": [
        "The agent always starts in (0, 0) and the environment is laid out in a grid-like fashion. Thus, we can compute the coordinates of the agent after actions such as 'north', 'south', 'east', or 'west'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC23G3hx1_TP"
      },
      "outputs": [],
      "source": [
        "# coordinates are a tuple (x, y)\n",
        "# direction is a string, 'north', 'south', 'east', 'west'\n",
        "def change_coordinates(coordinates, direction):\n",
        "    if direction == 'north':\n",
        "      return (coordinates[0], coordinates[1]+1)\n",
        "    elif direction == 'south':\n",
        "      return (coordinates[0], coordinates[1]-1)\n",
        "    elif direction == 'east':\n",
        "      return (coordinates[0]+1, coordinates[1])\n",
        "    elif direction == 'west':\n",
        "      return (coordinates[0]-1, coordinates[1])\n",
        "    return coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWM3l2XlQ1iy"
      },
      "source": [
        "Directions of travel are always north, south, east, west. Sometimes you might want to know which way is the opposite direction of travel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke7V0J-E3haW"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "def reverse_direction(dir):\n",
        "  if dir == \"north\":\n",
        "    return \"south\"\n",
        "  elif dir == \"south\":\n",
        "    return \"north\"\n",
        "  elif dir == \"west\":\n",
        "    return \"east\"\n",
        "  elif dir == \"east\":\n",
        "    return \"west\"\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xPomu9c3yy0"
      },
      "source": [
        "## The Test Environment Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OONxwd1N31Xk"
      },
      "source": [
        "This creates a new, special environment just for this homework. The environment keeps track of how many locations are in the world and which locations the agent has been to. The game terminates when the agent has visited all the locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLH9rsDVw_-U"
      },
      "outputs": [],
      "source": [
        "class TestTextWorldExpressEnv(TextWorldExpressEnv):\n",
        "\n",
        "  def __init__(self, serverPath=None, envStepLimit=100):\n",
        "    # Call the super constructor\n",
        "    super().__init__(serverPath, envStepLimit)\n",
        "    # Store the locations the agent has visited in a set of unique strings\n",
        "    self._visited_locations = set()\n",
        "    # The number of locations in the environment\n",
        "    self._num_locations = 0\n",
        "\n",
        "  ### Override for the environment load function\n",
        "  def load(self, gameName, gameParams):\n",
        "    # Call the super method\n",
        "    super().load(gameName, gameParams)\n",
        "    # Get the number of locations requested\n",
        "    match = re.search(r'numLocations\\=([0-9]+)', gameParams)\n",
        "    if match is not None and len(match.groups()) >= 1:\n",
        "      self._num_locations = int(match.group(1))\n",
        "\n",
        "  ### Override for the environment reset function\n",
        "  def reset(self, seed=None, gameFold=None, gameName=None, gameParams=None, generateGoldPath=False):\n",
        "    # Call the super method\n",
        "    obs, infos = super().reset(seed, gameFold, gameName, gameParams, generateGoldPath)\n",
        "    # get the beginning location\n",
        "    current_location = get_location_from_obs(obs)\n",
        "    # reset visited locations and initialize it with current location\n",
        "    self._visited_locations = set([current_location])\n",
        "    return obs, infos\n",
        "\n",
        "  def step(self, action:str):\n",
        "    obs, reward, done, infos = super().step(action)\n",
        "    current_location = get_location_from_obs(obs)\n",
        "    # Add current location to visited locations\n",
        "    if current_location is not None:\n",
        "      self._visited_locations.add(current_location)\n",
        "    # If the max number of locations have been visited, then set done = True, the game is over\n",
        "    if len(self._visited_locations) >= self._num_locations:\n",
        "      done = True\n",
        "    return obs, reward, done, infos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdJQRsjd1-ag"
      },
      "source": [
        "Register the new game type with the Gymnasium infrastructure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJPZF4pl4EhL"
      },
      "outputs": [],
      "source": [
        "gymnasium.register(id='TextWorldExpress-TestTextWorldExpressEnv-v0',\n",
        "                   entry_point='__main__:TestTextWorldExpressEnv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct16UWAK2DqP"
      },
      "source": [
        "Set up a test environment. It will be a CoinGame with doors and distractor items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C1tOkEV4T9O"
      },
      "outputs": [],
      "source": [
        "ENV = TestTextWorldExpressEnv(envStepLimit=100)\n",
        "SEED = 3 # you can change this\n",
        "GAME_TYPE = \"coin\" # do not change this\n",
        "GAME_PARAMS = \"numLocations=5,includeDoors=1,numDistractorItems=3\" # you can change this\n",
        "ENV.load(gameName=GAME_TYPE, gameParams=GAME_PARAMS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6egBTr32X7p"
      },
      "source": [
        "Resetting the environment makes sure it is ready to go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N8oQsB45GZc"
      },
      "outputs": [],
      "source": [
        "obs, infos = ENV.reset(seed = SEED, gameFold=\"train\", generateGoldPath=True)\n",
        "print(obs)\n",
        "print('\\nLocations the agent has visited:', ENV._visited_locations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJbq8SJYrv_7"
      },
      "source": [
        "# Implementing the Agent (TODO!!)\n",
        "\n",
        "In this section, you will implement the Agent, whose job is to explore the world.\n",
        "\n",
        "Add your code in the between the sections that say:\n",
        "```\n",
        "### YOUR CODE BELOW HERE ###\n",
        "\n",
        "### YOUR CODE ABOVE HERE ###\n",
        "```\n",
        "\n",
        "## Main Objective\n",
        "Your agent’s goal is to visit **every location in the world**\n",
        "\n",
        "- The world layout and number of rooms may vary.\n",
        "- The agent should work for any layout.\n",
        "- **Do not pick up the coin before visiting all locations (picking it up ends the game).**\n",
        "\n",
        "## What You Need to Do\n",
        "You will complete the `MyAgent` class, focusing mainly on the `choose_action()` method:\n",
        "\n",
        "- **`choose_action(self, infos)`**\n",
        "\n",
        "  - possible directions: `[north, south, east, west]`\n",
        "\n",
        "  - This method must choose a single action (e.g., `'move north'`, `'open door to north'`, etc.) and return it as a string.\n",
        "\n",
        "  - You should use `infos['look']` and `infos['validActions']` to decide what to do.\n",
        "\n",
        "  - This is where you’ll implement the logic to explore the world systematically.\n",
        "  - There will be a `run_agent()` loop, which will call `choose_action()` every iteration. If you need to keep track of any information from iteration to iteration, you may find it useful to create new class member variables in the constructor.\n",
        "\n",
        "## Helper Methods\n",
        "\n",
        "- `__init__`: you may modify this method to set up additional tracking variables that you can use in your implementation.\n",
        "\n",
        "- The `step` and `reset` methods are already implemented for you.\n",
        "\n",
        "  - `step`: Executes the chosen action in the environment and updates the agent’s internal state (such as current location and how to return to previous rooms).\n",
        "\n",
        "  - `reset`: Restarts the environment and reinitializes the agent’s state so it can begin exploring from the start again.\n",
        "\n",
        "\n",
        "**Hints:**\n",
        "- Keep track of what rooms you have been to.\n",
        "- Keep track of what directions you've tried from every room.\n",
        "- Keep track of which doors you've opened.\n",
        "- Open doors before trying to move in a direction.\n",
        "- If you've exhausted all directions from any given room, remember how you got. there and go to another room that hasn't been exhausted.\n",
        "- You can create whatever member variables you need, and create helper function either inside the class or outside in separate cells.\n",
        "- You cannot call `step()` from `choose_action()`.\n",
        "- You should not be accessing `env._visited_locations` or `env._num_locations`. You can keep track of the former in your agent. Your solution should be written so that it does not need to know the latter.\n",
        "- You should not make any changes to the `TestTextWorldExpressEnv` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i1wUQPirymT"
      },
      "outputs": [],
      "source": [
        "from typing import overload\n",
        "#export\n",
        "class MyAgent:\n",
        "\n",
        "  ### Constructor\n",
        "  def __init__(self, env):\n",
        "    self.coordinates = (0, 0) # initialize the agent's coordinates to (x, y) = (0, 0)\n",
        "    self.location = None # the name of the agent's location as a string e.g., 'backyard'\n",
        "    self.env = env\n",
        "    self.doors = {} # how many doors opened per location\n",
        "    self.exploring = {} # how many directions moved per location\n",
        "    self.parent_directions = {} # what direction to go to get back to parent\n",
        "    self.previous_location = None\n",
        "\n",
        "    ### (OPTIONAL) initialize additional member variables below here:\n",
        "    ### YOUR CODE BELOW HERE ###\n",
        "    self.visited_rooms = set()\n",
        "    self.last_taken ='move east'\n",
        "    ### YOUR CODE ABOVE HERE ###\n",
        "\n",
        "\n",
        "  ### This function should \"think\" about which action to perform and return a string\n",
        "  ### The string should be one of the infos['validActions'].\n",
        "  ### You can do whatever you want to make this happen.\n",
        "  ### Do not calls self.step() from this function.\n",
        "  def choose_action(self, infos):\n",
        "    observation = infos['look']\n",
        "    valid_actions = infos['validActions']\n",
        "    action = random.choice(infos['validActions'])\n",
        "    ### YOUR CODE BELOW HERE ###\n",
        "    # bad cause traversing list that I am currently modifying in place\n",
        "    true_valid_actions = []\n",
        "    for action in valid_actions:\n",
        "      if \"close door\" not in action and \"coin\" not in action:\n",
        "        true_valid_actions.append(action)\n",
        "\n",
        "    # get last word in direction to see if we can open a door to that direction\n",
        "    last_direction_taken = self.last_taken.split()[-1]\n",
        "\n",
        "    # want to continue prev direction\n",
        "    if self.last_taken in true_valid_actions:\n",
        "      action = self.last_taken\n",
        "    \n",
        "    \n",
        "    elif \"open door to \" + last_direction_taken in true_valid_actions:\n",
        "      action = \"open door to \" + last_direction_taken\n",
        "    else:\n",
        "      # pick another direction\n",
        "      action = random.choice(true_valid_actions)\n",
        "      self.last_taken = action\n",
        "\n",
        "    ### YOUR CODE ABOVE HERE ###\n",
        "    return action\n",
        "\n",
        "  ### Tell the agent to execute an action.\n",
        "  def step(self, action):\n",
        "    # Run the action in the environment\n",
        "    obs, reward, done, infos = self.env.step(action)\n",
        "    self.previous_location = self.location\n",
        "    self.location = get_location_from_obs(infos['look'])\n",
        "    if 'move' in action and self.location != self.previous_location and self.location not in self.parent_directions:\n",
        "      direction_traveled = action[action.rfind(' '):].strip()\n",
        "      self.parent_directions[self.location] = reverse_direction(direction_traveled)\n",
        "    return obs, reward, done, infos\n",
        "\n",
        "  ### Reset the agent and the world\n",
        "  def reset(self, seed = 3):\n",
        "    obs, infos = self.env.reset(gameFold=\"train\", generateGoldPath=True)\n",
        "    self.location = get_location_from_obs(infos['look'])\n",
        "    return obs, infos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCIm8cP_5lpb"
      },
      "source": [
        "Let's test your agent with a single action. You can run this over and over again to see what happens. If you haven't implemented your own `choose_action`, you will execute a random action each time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7FGRD3s3DJ2"
      },
      "outputs": [],
      "source": [
        "agent = MyAgent(ENV)\n",
        "observation, infos = agent.reset(SEED)\n",
        "print(observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ulkxv0A_7Rz0"
      },
      "outputs": [],
      "source": [
        "action = agent.choose_action(infos)\n",
        "print(\"action:\", action, '\\n')\n",
        "observation, reward, done, infos = agent.step(action)\n",
        "print(observation)\n",
        "print(\"\\nVisited:\", ENV._visited_locations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Nbu1wnBCjV"
      },
      "source": [
        "This function will run a loop that asks the agent to choose and action and then executes it. It will terminate under the following conditions: (a) the agent has visited all rooms, (b) the agent has picked up the coin, (c) it has reached a maximum number of steps.\n",
        "\n",
        "The function takes four arguments:\n",
        "- `num_locations`: the number of rooms in the world.\n",
        "- `seed`: controls the random generation of the world for repeatability.\n",
        "- `timeout`: maximum number of steps\n",
        "- `verbose`: use print statements when True\n",
        "\n",
        "**This function returns true only if the agent has visited all the rooms.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHNaLPar6DpE"
      },
      "outputs": [],
      "source": [
        "def run_agent(num_locations = 5, seed = 3, timeout = 100, verbose = True):\n",
        "  # Create a new environment\n",
        "  env = TestTextWorldExpressEnv(envStepLimit=100)\n",
        "  # load the environment with the correct number of locations\n",
        "  params = \"numLocations={loc},includeDoors=1,numDistractorItems=3\".format(loc = num_locations)\n",
        "  env.load(gameName=\"coin\", gameParams=params)\n",
        "  # Create a new agent\n",
        "  agent = MyAgent(env = env)\n",
        "  # Reset the agent and the world\n",
        "  observation, infos = agent.reset(seed = seed)\n",
        "  if verbose:\n",
        "    print(observation)\n",
        "  done = False # is the environment in a terminal state?\n",
        "  num_steps = 0 # keep track of steps taken\n",
        "  # The execution loop, until the environment is terminal or max steps reached\n",
        "  while not done and num_steps < timeout:\n",
        "    # Agent picks an action\n",
        "    action = agent.choose_action(infos)\n",
        "    if verbose:\n",
        "      print(\"\\naction:\", action, '\\n')\n",
        "    # Agent executes the action\n",
        "    observation, reward, done, infos = agent.step(action)\n",
        "    if verbose:\n",
        "      print(observation)\n",
        "      print('\\nNum locations visited:', len(env._visited_locations))\n",
        "    # Update step count\n",
        "    num_steps = num_steps + 1\n",
        "  ## For debugging purposes:\n",
        "  locations_visited = set(env._visited_locations)\n",
        "  # Assert: We have visited all rooms, reached max number of steps, or picked up the coin\n",
        "  # Return true only if we have visited the correct number of locations\n",
        "  return len(env._visited_locations) == env._num_locations, locations_visited\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYk20Ab7CRF6"
      },
      "source": [
        "Run the agent. **You can change the parameters if you want**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TOkoFlB-7Vg"
      },
      "outputs": [],
      "source": [
        "num_locations = 5 # you can change this parameter\n",
        "success, visited_locations = run_agent(num_locations=num_locations, seed=3, timeout=100, verbose=False) # change verbose to True for more debugging information\n",
        "print(\"Success:\", success)\n",
        "print(\"Locations Visited:\", visited_locations)\n",
        "print(\"Expected number of locations visited\", num_locations)\n",
        "# adding to check what locations i'm missing\n",
        "print(\"Expected locations visited: \", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H4vatUcqKet"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexLJBgHRnwG"
      },
      "source": [
        "The code below will run your agent a fixed number of times with increasing number of rooms (3 through 10) and with random seeds. Your score will be determined using the scoring policy described in the section below.\n",
        "\n",
        "For debugging purposes you may find it helpful to fix the seed temporarily for reproducability, however, your solution should work on a variety of seeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfZti8WiKqQY"
      },
      "outputs": [],
      "source": [
        "test_seeds = list(range(0, 100, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIe14XGQqMQZ"
      },
      "outputs": [],
      "source": [
        "def local_evaluation(testing_seeds):\n",
        "    successes = 0\n",
        "    num_trials = len(testing_seeds)\n",
        "    for n in range(len(testing_seeds)):\n",
        "      seed = testing_seeds[n]\n",
        "      num_locations = min(3 + (n//2), 10)\n",
        "      print(\"trial:\", n, \"locations:\", num_locations, \"seed:\", seed)\n",
        "\n",
        "      success, visited_locations = run_agent(num_locations = num_locations,\n",
        "                         seed = seed,\n",
        "                         timeout = 100,\n",
        "                         verbose = False,\n",
        "                         )\n",
        "      print(\"result:\", success)\n",
        "      successes = successes + (1 if success == True else 0)\n",
        "    print(\"\\nsuccesses:\", successes)\n",
        "    print(\"num trials:\", num_trials)\n",
        "    raw_score = successes / num_trials\n",
        "    if raw_score >= 0.6:\n",
        "        score = 100.0\n",
        "    else:\n",
        "        score = (raw_score / 0.6) * 100.0\n",
        "    print(\"SCORE [0, 100]:\", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XGb3nqcKqQZ"
      },
      "outputs": [],
      "source": [
        "local_evaluation(testing_seeds=test_seeds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoUuCkcJKqQZ"
      },
      "source": [
        "# Grading\n",
        "\n",
        "Your agent will be evaluated by running it on a range of random seeds on a variety of environments and game variations, as in the local evaluation above.\n",
        "\n",
        "- These test configurations will not include invalid game settings or unsolvable cases — the goal is simply to check that your solution generalizes and is not hardcoded.\n",
        "\n",
        "- The tests will be visible in Gradescope and are the same as the local evaluation given. Future assignments will have hidden tests in Gradescope (not visible to you). Your final grade will be based on performance across both visible and hidden tests.\n",
        "\n",
        "## Scoring Policy\n",
        "\n",
        "- If your agent achieves a success rate of 60% or higher, you will receive full credit (100%).\n",
        "- If your agent’s success rate is below 60%, then you will receive partial credit on a linear scale, calculated as:\n",
        "\n",
        "$$\n",
        "\\text{Grade} = \\frac{\\text{Success Rate}}{0.60} \\times 100\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNOOCEoBKqQZ"
      },
      "source": [
        "# Submission Instructions\n",
        "\n",
        "Upload this notebook with the name `submission.ipynb` file to Gradescope. The autograder will **only** run successfully if your file is named this way. You must ensure that you have removed all print statements from **your** code, or the autograder may fail to run. Excessive print statements will also result in muddled test case outputs, which makes it more difficult to interpret your score.\n",
        "\n",
        "We've added appropriate comments to the top of certain cells for the autograder to export (`# export`). You do NOT have to do anything (e.g. remove print statements) to cells we have provided - anything related to those have been handled for you. You are responsible for ensuring your own code has no syntax errors or unnecessary print statements. You **CANNOT** modify the export comments at the top of the cells, or the autograder will fail to run on your submission. This includes adding a line above the `# export` line.\n",
        "\n",
        "You should not **add** any cells that your code requires to the notebook when submitting. You're welcome to add any code as you need to extra cells when testing, but they will not be graded. Only the provided cells will be graded. As mentioned in the top of the notebook, **any helper functions that you add should be nested within the function that uses them.**\n",
        "\n",
        "If you encounter any issues with the autograder, please feel free to make a post on Ed Discussion. We highly recommend making a public post to clarify any questions, as it's likely that other students have the same questions as you! If you have a question that needs to be private, please make a private post."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
